{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "import pymorphy2\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "morph = pymorphy2.MorphAnalyzer()\n",
    "tokenizer = RegexpTokenizer(r'\\w+')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pandas.read_csv(\"C:\\\\Users\\\\sante\\\\Desktop\\\\мой нлп - Лист1-2.csv\", encoding=\"utf-8\")\n",
    "\n",
    "# тестовые данные\n",
    "valid = df[\"title\"].isin(['Интерстеллар', \"Омерзительная восьмерка\", \"Тройной форсаж: Токийский дрифт\"])\n",
    "test = df[valid]\n",
    "del test['title']\n",
    "\n",
    "# удалили наши данные(оставили данные для обучения)\n",
    "df = df.loc[df['title'] != \"Интерстеллар\"]\n",
    "df = df.loc[df['title'] != \"Омерзительная восьмерка\"]\n",
    "df = df.loc[df['title'] != \"Тройной форсаж: Токийский дрифт\"]\n",
    "del df['title']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.head of                                                   text  label\n",
       "0    Дон Блут – один из самых известных анимационны...     -1\n",
       "1    Отрицательных рецензий на этот мультфильм очен...     -1\n",
       "2    \\nЧестно признаюсь: в детстве я если и смотрел...     -1\n",
       "3    \\nВпервые я познакомилась с творением студии '...     -1\n",
       "4    \\nЯ узнала про мультфильм 'Анастасия' на продл...     -1\n",
       "..                                                 ...    ...\n",
       "585  Питер Джексон уже не тот...  Пишу как человек,...     -1\n",
       "586  Ждали-ждали - дождались  Около двух лет назад ...     -1\n",
       "587  Три часа скукоты  В том, что «Хоббит: Нежданно...     -1\n",
       "588  что-то случилось с любимым нами Средиземьем  В...     -1\n",
       "589  Детям фильм смотреть нельзя  Фильм не понравил...     -1\n",
       "\n",
       "[590 rows x 2 columns]>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenizeWord(word):\n",
    "    word = tokenizer.tokenize(word)\n",
    "    if len(word) == 1:\n",
    "        word = word[0]\n",
    "    else:\n",
    "        word = \"\"\n",
    "    return word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "uniqWords = []\n",
    "tupleIndex = 0\n",
    "sentences = []\n",
    "for tuple in df.values:\n",
    "    tupleIndex+=1\n",
    "    words = tuple[0].split()\n",
    "    wordsList = []\n",
    "    for word in words:\n",
    "        wordNF = tokenizeWord(morph.parse(word)[0].normal_form)\n",
    "        uniqWords.append(wordNF)\n",
    "        wordsList.append(wordNF)\n",
    "    sentences.append(wordsList)\n",
    "tupleIndex = 0\n",
    "testSentences = []\n",
    "for tuple in test.values:\n",
    "    tupleIndex+=1\n",
    "    words = tuple[0].split()\n",
    "    wordsList = []\n",
    "    for word in words:\n",
    "        wordNF = tokenizeWord(morph.parse(word)[0].normal_form)\n",
    "        uniqWords.append(wordNF)\n",
    "        wordsList.append(wordNF)\n",
    "    testSentences.append(wordsList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing\n",
    "from gensim.models import Word2Vec\n",
    "uniqWords = set(uniqWords)\n",
    "model = Word2Vec(sentences=sentences,min_count=1,size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('амели', 0.9998214244842529), ('начинать', 0.999721109867096), ('всегда', 0.9996988773345947), ('реальность', 0.9996824264526367), ('времени', 0.9996778964996338), ('тут', 0.9996770620346069), ('смысл', 0.9996719360351562), ('тоже', 0.9996703863143921), ('теперь', 0.9996680021286011), ('время', 0.9996675252914429)]\n",
      "[('посмотреть', 0.9988816380500793), ('ни', 0.9987820982933044), ('чем', 0.998660683631897), ('только', 0.9985199570655823), ('шедевр', 0.9984079599380493), ('кто', 0.9983744621276855), ('забыть', 0.9982613921165466), ('ещё', 0.9982547163963318), ('единственное', 0.9982055425643921), ('несмотря', 0.9981734752655029)]\n",
      "[('много', 0.9996849298477173), ('все', 0.9996049404144287), ('ты', 0.9995788931846619), ('понимать', 0.9995312690734863), ('мало', 0.9995127320289612), ('нет', 0.9995114803314209), ('мы', 0.9995007514953613), ('она', 0.9994980692863464), ('вот', 0.999492883682251), ('даже', 0.9994525909423828)]\n",
      "[('знаменитый', 0.9984984993934631), ('отличный', 0.9984617829322815), ('питер', 0.9984439611434937), ('заслуживать', 0.9984210133552551), ('мальчик', 0.998411238193512), ('великолепный', 0.9982891082763672), ('работа', 0.9982714653015137), ('джон', 0.9982653856277466), ('оставить', 0.998235285282135), ('визуальный', 0.9982322454452515)]\n",
      "[('героиня', 0.9996254444122314), ('героя', 0.9994399547576904), ('сцена', 0.9992469549179077), ('персонаж', 0.9992148876190186), ('сторона', 0.9991887807846069), ('песня', 0.9991779327392578), ('два', 0.9991455078125), ('лев', 0.9991370439529419), ('джон', 0.9991309642791748), ('единственный', 0.9990845918655396)]\n"
     ]
    }
   ],
   "source": [
    "print(model.wv.most_similar('конец'))\n",
    "print(model.wv.most_similar('фильм'))\n",
    "print(model.wv.most_similar('он'))\n",
    "print(model.wv.most_similar('режиссер'))\n",
    "print(model.wv.most_similar('герой'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.02639376 -0.06133854 -0.03379047  0.026828    0.00297044  0.04419322\n",
      "  0.02815407  0.04377708 -0.01719869  0.08568732  0.0030121  -0.03489447\n",
      "  0.03668172  0.00902367 -0.04218019  0.02299653 -0.01711602 -0.05457292\n",
      "  0.01265272  0.02959881 -0.02873543  0.02561061 -0.00200684  0.04097864\n",
      " -0.04696902  0.03350537 -0.00923586 -0.04765229  0.03512321 -0.0662681\n",
      "  0.01541122 -0.07415998]\n"
     ]
    }
   ],
   "source": [
    "def getMiddleValue(array):\n",
    "    sum = 0\n",
    "    for i in array:\n",
    "        sum += i\n",
    "    return sum/len(array)\n",
    "print(model.wv['блут'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pandas.DataFrame(columns = uniqWords)\n",
    "index = 0\n",
    "for comment in sentences:\n",
    "    index += 1\n",
    "    commentLength = len(comment)\n",
    "    arrayDict = dict.fromkeys(uniqWords, 0)\n",
    "    for word in comment:\n",
    "        vector = model.wv[word]\n",
    "        mid_vector = list(map(lambda x: x/commentLength, vector))\n",
    "        value = getMiddleValue(mid_vector)\n",
    "        arrayDict[word] = value\n",
    "    X_train.loc[index] = list(arrayDict.values())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train = df[\"label\"]\n",
    "Y_test = test[\"label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "randomForestCLF = RandomForestClassifier(max_depth=20, random_state=0).fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = pandas.DataFrame(columns = uniqWords)\n",
    "index = 0\n",
    "for comment in testSentences:\n",
    "    index += 1\n",
    "    commentLength = len(comment)\n",
    "    arrayDict = dict.fromkeys(uniqWords, 0)\n",
    "    for word in comment:\n",
    "        if word in list(model.wv.vocab.keys()):\n",
    "            vector = model.wv[word]\n",
    "            mid_vector = list(map(lambda x: x/commentLength, vector))\n",
    "            value = getMiddleValue(mid_vector)\n",
    "            arrayDict[word] = value\n",
    "        else:\n",
    "            arrayDict[word] = 0\n",
    "    X_test.loc[index] = list(arrayDict.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "randomForestPredict = randomForestCLF.predict(X_test)\n",
    "randomForestMetric = precision_recall_fscore_support(test[\"label\"].values, randomForestPredict, average='weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.39940518890483023, 0.4111111111111111, 0.3939054137223248, None)\n"
     ]
    }
   ],
   "source": [
    "print(randomForestMetric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
