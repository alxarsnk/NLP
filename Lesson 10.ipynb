{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pandas.read_csv(\"C:\\\\Users\\\\sante\\\\Desktop\\\\мой нлп - Лист1-2.csv\", encoding=\"utf-8\")\n",
    "\n",
    "# тестовые данные\n",
    "valid = df[\"title\"].isin(['Интерстеллар', \"Омерзительная восьмерка\", \"Тройной форсаж: Токийский дрифт\"])\n",
    "test = df[valid]\n",
    "del test['title']\n",
    "\n",
    "# удалили наши данные(оставили данные для обучения)\n",
    "df = df.loc[df['title'] != \"Интерстеллар\"]\n",
    "df = df.loc[df['title'] != \"Омерзительная восьмерка\"]\n",
    "df = df.loc[df['title'] != \"Тройной форсаж: Токийский дрифт\"]\n",
    "del df['title']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.head of                                                   text  label\n",
       "0    Дон Блут – один из самых известных анимационны...     -1\n",
       "1    Отрицательных рецензий на этот мультфильм очен...     -1\n",
       "2    \\nЧестно признаюсь: в детстве я если и смотрел...     -1\n",
       "3    \\nВпервые я познакомилась с творением студии '...     -1\n",
       "4    \\nЯ узнала про мультфильм 'Анастасия' на продл...     -1\n",
       "..                                                 ...    ...\n",
       "585  Питер Джексон уже не тот...  Пишу как человек,...     -1\n",
       "586  Ждали-ждали - дождались  Около двух лет назад ...     -1\n",
       "587  Три часа скукоты  В том, что «Хоббит: Нежданно...     -1\n",
       "588  что-то случилось с любимым нами Средиземьем  В...     -1\n",
       "589  Детям фильм смотреть нельзя  Фильм не понравил...     -1\n",
       "\n",
       "[590 rows x 2 columns]>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " df.head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenizeWord(word):\n",
    "    word = tokenizer.tokenize(word)\n",
    "    if len(word) == 1:\n",
    "        word = word[0]\n",
    "    else:\n",
    "        word = \"\"\n",
    "    return word\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymorphy2\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "morph = pymorphy2.MorphAnalyzer()\n",
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "uniqWords = []\n",
    "tupleIndex = 0\n",
    "sentences = []\n",
    "texts = []\n",
    "for tuple in df.values:\n",
    "    tupleIndex+=1\n",
    "    texts.append(tuple[0])\n",
    "    words = tuple[0].split()\n",
    "    wordsList = []\n",
    "    for word in words:\n",
    "        wordNF = tokenizeWord(morph.parse(word)[0].normal_form)\n",
    "        uniqWords.append(wordNF)\n",
    "        wordsList.append(wordNF)\n",
    "    sentences.append(wordsList)\n",
    "tupleIndex = 0\n",
    "for tuple in test.values:\n",
    "    tupleIndex+=1\n",
    "    texts.append(tuple[0])\n",
    "    words = tuple[0].split()\n",
    "    wordsList = []\n",
    "    for word in words:\n",
    "        wordNF = tokenizeWord(morph.parse(word)[0].normal_form)\n",
    "        uniqWords.append(wordNF)\n",
    "        wordsList.append(wordNF)\n",
    "    sentences.append(wordsList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim import corpora\n",
    "dictionary = corpora.Dictionary(sentences)\n",
    "corpus = [dictionary.doc2bow(sentence) for sentence in sentences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump(corpus, open('corpus.pkl', 'wb'))\n",
    "dictionary.save('dictionary.gensim')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.001*\"амели\" + 0.001*\"мёртвый\" + 0.001*\"героиня\" + 0.001*\"вдохновлять\" + 0.001*\"жён\" + 0.001*\"и\" + 0.001*\"феноменальный\" + 0.001*\"собирать\" + 0.001*\"не\" + 0.001*\"треть\" + 0.001*\"завоевать\" + 0.001*\"наполнить\" + 0.001*\"в\" + 0.000*\"остроумный\" + 0.000*\"персонажами\"\n",
      "0.000*\"периодичность\" + 0.000*\"отказать\" + 0.000*\"стильность\" + 0.000*\"вачивски\" + 0.000*\"оценки\" + 0.000*\"страданиях\" + 0.000*\"окружают\" + 0.000*\"станут\" + 0.000*\"классик\" + 0.000*\"новатор\" + 0.000*\"вачовски\" + 0.000*\"и\" + 0.000*\"в\" + 0.000*\"не\" + 0.000*\"\"\n",
      "0.001*\"счету\" + 0.001*\"лиза\" + 0.001*\"тарантиновский\" + 0.001*\"достоверность\" + 0.001*\"и\" + 0.001*\"\" + 0.001*\"унижать\" + 0.001*\"размазать\" + 0.001*\"элита\" + 0.001*\"явления\" + 0.001*\"полковник\" + 0.001*\"конкуренция\" + 0.001*\"негритят\" + 0.001*\"временной\" + 0.001*\"сегодняшний\"\n",
      "0.040*\"и\" + 0.029*\"в\" + 0.023*\"\" + 0.022*\"не\" + 0.015*\"что\" + 0.014*\"на\" + 0.014*\"он\" + 0.013*\"это\" + 0.012*\"я\" + 0.011*\"с\" + 0.011*\"фильм\" + 0.009*\"но\" + 0.009*\"весь\" + 0.008*\"как\" + 0.008*\"который\"\n",
      "0.001*\"и\" + 0.001*\"восьмерке\" + 0.001*\"\" + 0.001*\"добро\" + 0.001*\"жалко\" + 0.001*\"мультфильм\" + 0.001*\"we\" + 0.001*\"линкольн\" + 0.001*\"майор\" + 0.001*\"низкосортный\" + 0.001*\"заслугам\" + 0.001*\"установка\" + 0.001*\"поверьте\" + 0.001*\"уоррен\" + 0.001*\"зло\"\n",
      "0.027*\"и\" + 0.026*\"в\" + 0.020*\"не\" + 0.019*\"что\" + 0.016*\"\" + 0.013*\"на\" + 0.012*\"это\" + 0.010*\"фильм\" + 0.009*\"я\" + 0.009*\"с\" + 0.008*\"но\" + 0.008*\"весь\" + 0.007*\"как\" + 0.007*\"который\" + 0.006*\"а\"\n",
      "0.000*\"гласить\" + 0.000*\"семей\" + 0.000*\"вольнодумец\" + 0.000*\"речка\" + 0.000*\"страниц\" + 0.000*\"киттингс\" + 0.000*\"мальчишки\" + 0.000*\"неприемлемы\" + 0.000*\"педагогический\" + 0.000*\"мечтами\" + 0.000*\"кружка\" + 0.000*\"грусти\" + 0.000*\"вдохновляет\" + 0.000*\"идеализированный\" + 0.000*\"нереального\"\n",
      "0.009*\"\" + 0.007*\"не\" + 0.007*\"и\" + 0.006*\"на\" + 0.006*\"в\" + 0.004*\"к\" + 0.003*\"он\" + 0.003*\"с\" + 0.002*\"но\" + 0.002*\"а\" + 0.002*\"как\" + 0.002*\"бы\" + 0.002*\"от\" + 0.002*\"я\" + 0.002*\"за\"\n",
      "0.036*\"и\" + 0.031*\"в\" + 0.029*\"\" + 0.024*\"не\" + 0.016*\"что\" + 0.013*\"это\" + 0.013*\"фильм\" + 0.012*\"на\" + 0.010*\"весь\" + 0.010*\"он\" + 0.009*\"с\" + 0.008*\"быть\" + 0.008*\"но\" + 0.008*\"а\" + 0.008*\"я\"\n",
      "0.033*\"и\" + 0.029*\"в\" + 0.019*\"\" + 0.017*\"не\" + 0.011*\"что\" + 0.010*\"с\" + 0.010*\"на\" + 0.009*\"он\" + 0.008*\"это\" + 0.007*\"фильм\" + 0.007*\"весь\" + 0.007*\"но\" + 0.007*\"как\" + 0.006*\"который\" + 0.006*\"а\"\n"
     ]
    }
   ],
   "source": [
    "import gensim\n",
    "NUM_TOPICS = 10\n",
    "ldamodel = gensim.models.ldamodel.LdaModel(corpus, num_topics = NUM_TOPICS, id2word=dictionary, passes=15)\n",
    "ldamodel.save('model5.gensim')\n",
    "topics = ldamodel.print_topics(num_words=15)\n",
    "for topic in topics:\n",
    "    print(topic[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Coherence Score:  0.2949455060712663\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from gensim.models import CoherenceModel\n",
    "\n",
    "coherence_model_lda = CoherenceModel(model=ldamodel, texts=sentences, dictionary=dictionary, coherence='c_v')\n",
    "coherence_lda = coherence_model_lda.get_coherence()\n",
    "print('\\nCoherence Score: ', coherence_lda)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
